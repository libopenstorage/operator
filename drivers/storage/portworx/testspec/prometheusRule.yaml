apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: portworx
  name: portworx
  namespace: kube-test
spec:
  groups:
  - name: portworx.rules
    rules:
    - alert: PortworxVolumeUsageCritical
      annotations:
        description: Portworx volume {{$labels.volumeid}} on {{$labels.instance}} is over 80% used for
          more than 5 minutes.
        summary: Portworx volume capacity is at {{$value}}% used.
      expr: 100 * (px_volume_usage_bytes / px_volume_capacity_bytes) > 80
      for: 5m
      labels:
        issue: Portworx volume {{$labels.volumeid}} usage on {{$labels.instance}} is critical.
        severity: critical
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxVolumeUsage
      annotations:
        description: Portworx volume {{$labels.volumeid}} on {{$labels.instance}} is over 70% used for
          more than 5 minutes.
        summary: Portworx volume {{$labels.volumeid}} on {{$labels.instance}} is at {{$value}}% used.
      expr: 100 * (px_volume_usage_bytes / px_volume_capacity_bytes) > 70
      for: 5m
      labels:
        issue: Portworx volume {{$labels.volumeid}} usage on {{$labels.instance}} is high.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxVolumeNotInQuorum
      annotations:
        description: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is out of quorum. Please check all nodes with that volume replicas are online.
        summary: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is out of quorum.
      expr: px_volume_replication_status == 1
      labels:
        issue: Portworx volume out of quorum.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxVolumeInResync
      annotations:
        description: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is in resync state.
        summary: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is in resync state.
      expr: px_volume_replication_status == 2
      labels:
        issue: Portworx volume in resync state.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxVolumeDegraded
      annotations:
        description: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is in degraded state. Please check all nodes with that volume replicas are online.
        summary: Portworx volume {{$labels.volumeid}} from cluster {{$labels.cluster}} is in degraded state.
      expr: px_volume_replication_status == 3
      labels:
        issue: Portworx volume in degraded state.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxStorageUsageCritical
      annotations:
        description: Portworx storage on {{$labels.instance}} is over 80% used
          for more than 5 minutes.
        summary: Portworx storage on {{$labels.instance}} is at {{$value}}% used.
      expr: 100 * (px_cluster_disk_utilized_bytes / px_cluster_disk_total_bytes) > 80
      for: 5m
      labels:
        issue: Portworx storage usage on {{$labels.instance}} is critical.
        severity: critical
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxStorageUsage
      annotations:
        description: Portworx storage on {{$labels.instance}} is over 70% used
          for more than 5 minutes.
        summary: Portworx storage on {{$labels.instance}} is at {{$value}}% used.
      expr: 100 * (px_cluster_disk_utilized_bytes / px_cluster_disk_total_bytes) > 70
      for: 5m
      labels:
        issue: Portworx storage usage on {{$labels.instance}} is high.
        severity: warning
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxStorageWillFill
      annotations:
        description: Portworx storage on {{$labels.instance}} is over 70% full
          and is predicted to fill within 2 weeks.
        summary: Portworx storage on {{$labels.instance}} is over 70% full and
          is predicted to fill within 2 weeks.
      expr: (100 * (1 - (px_cluster_disk_utilized_bytes / px_cluster_disk_total_bytes)))
        < 30 and predict_linear(px_cluster_disk_available_bytes[1h], 14 * 86400) <
        0
      for: 10m
      labels:
        issue: Portworx storage on {{$labels.instance}} is predicted to fill within
          2 weeks.
        severity: warning
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PortworxStorageNodeDown
      annotations:
        description: '{{ $value | printf "%.0f" }} Portworx node(s) are in StorageDown state for more than 5 minutes.'
        summary: One or more Portworx nodes are in StorageDown state.
      expr: max by(cluster, clusterUUID) (px_cluster_status_nodes_storage_down) > 0
      for: 5m
      labels:
        issue: Portworx Storage Node is Offline.
        severity: critical
        resource_type: portworx-cluster
        resource_name: "{{$labels.cluster}}"
        scrape_target_type: portworx-cluster
        scrape_target_name: "{{$labels.cluster}}"
    - alert: PortworxQuorumUnhealthy
      annotations:
        description: Portworx cluster Quorum Unhealthy for more than 5 minutes.
        summary: Portworx Quorum Unhealthy.
      expr: max by(cluster, clusterUUID) (px_cluster_status_cluster_quorum) > 1
      for: 5m
      labels:
        issue: Portworx Quorum Unhealthy.
        severity: critical
        resource_type: portworx-cluster
        resource_name: "{{$labels.cluster}}"
        scrape_target_type: portworx-cluster
        scrape_target_name: "{{$labels.cluster}}"
    - alert: PortworxMemberDown
      annotations:
        description: '{{ $value | printf "%.0f" }} Portworx cluster member(s) have been down for more than 5 minutes.'
        summary: One or more Portworx cluster members are down.
      expr: (max by(cluster, clusterUUID) (px_cluster_status_size) - max by(cluster, clusterUUID) (px_cluster_status_nodes_online))
        > 0
      for: 5m
      labels:
        issue: One or more Portworx cluster members are down.
        severity: critical
        resource_type: portworx-cluster
        resource_name: "{{$labels.cluster}}"
        scrape_target_type: portworx-cluster
        scrape_target_name: "{{$labels.cluster}}"
    - alert: PXBackupError
      annotations:
        description: Failed to take backup for volume {{$labels.volumename}} with error {{$labels.error_string}}.
        summary: Failed to take backup for volume {{$labels.volumename}}.
      expr: px_backup_stats_backup_status == 2
      labels:
        issue: Cloudsnap backup error.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumename}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PXKvdbNodeViewUnhealthy
      annotations:
        description: Portworx node {{$labels.node}} from cluster {{$labels.cluster}} is unable to talk to kvdb. Please check the KVDB health and node's connection to KVDB.
        summary: Portworx node {{$labels.node}} is unable to talk to kvdb.
      expr: px_kvdb_health_state_node_view == 2
      for: 5m
      labels:
        issue: Portworx node {{$labels.node}} is unable to talk to kvdb.
        severity: critical
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PXKvdbClusterViewUnhealthy
      annotations:
        description: Portworx node {{$labels.node}} from cluster {{$labels.cluster}} is reporting that the cluster is unable to talk to kvdb. Please check KVDB health and the node's connection to KVDB and the other nodes in the cluster.
        summary: Portworx cluster {{$labels.cluster}} is unable to talk to kvdb.
      expr: px_kvdb_health_state_cluster_view == 2
      labels:
        issue: Portworx cluster {{$labels.cluster}} is unable to talk to kvdb.
        severity: critical
        resource_type: portworx-cluster
        resource_name: "{{$labels.cluster}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
  - name: Portworx PoolResize Alerts
    rules:
    - alert: PoolExpandSuccessful
      annotations:
        description: Pool {{$labels.POOL}} from node {{$labels.instance}}, from Portworx cluster {{$labels.clusterid}} successfully expanded.
        summary: Portworx pool {{$labels.POOL}} successfully expanded.
      expr: px_alerts_poolexpandsuccessful > 1
      labels:
        issue: Portworx pool expand successful.
        severity: warning
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: PoolExpandFailure
      annotations:
        description: Pool expansion for pool {{$labels.POOL}} from node {{$labels.instance}}, from Portworx cluster {{$labels.clusterid}} failed. Please check Portworx alerts for more details.
        summary: Pool expansion for pool {{$labels.POOL}} failed.
      expr: px_alerts_poolexpandfailed > 1
      labels:
        issue: Portworx pool expand failure.
        severity: critical
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
  - name: Portworx VolumeResize Alerts
    rules:
    - alert: VolumeResizeSuccessful
      annotations:
        description: Portworx volume {{$labels.volumeid}} from cluster {{$labels.clusterid}} successfully resized.
        summary: Portworx volume {{$labels.volumeid}} successfully resized.
      expr: px_alerts_volumeresizesuccessful == 1
      labels:
        issue: Portworx volume resize successful.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: VolumeResizeDeferred
      annotations:
        description: Volume resize for volume {{$labels.volumeid}} from Portworx cluster {{$labels.clusterid}} deferred. Please check Portworx alerts for more details.
        summary: Volume resize for volume {{$labels.volumeid}} deferred.
      expr: px_alerts_volumeresizedeferred == 1
      labels:
        issue: Portworx volume resize deferred.
        severity: warning
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
    - alert: VolumeResizeFailed
      annotations:
        description: Volume resize for volume {{$labels.volumeid}} from Portworx cluster {{$labels.clusterid}} failed. Please check Portworx alerts for more details.
        summary: Volume resize for volume {{$labels.volumeid}} failed.
      expr: px_alerts_volumeresizefailed == 1
      labels:
        issue: Portworx volume resize failure.
        severity: critical
        resource_type: portworx-volume
        resource_name: "{{$labels.volumeid}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
  - name: Portworx License Alerts
    rules:
    - alert: PortworxLicenseExpiry
      # Tuneable license-expiry alert, reported by each node individually, works for both regular and floating licenses.
      # - note: if #days drops into negative, the license has already expired
      expr: px_node_status_license_expiry < 5
      labels:
        issue: Portworx license (or license lease) expiring.
        severity: warning
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
      annotations:
        summary: Portworx license (or license lease) expiring in {{$value}} days.
        description: Portworx node {{$labels.node}} of cluster {{$labels.cluster}} reports
          its license (or license lease) expiring in {{$value}} days.
    - alert: PortworxLicenseServerDown
      expr: px_alerts_licenseserverdown > 0
      labels:
        severity: warning
        issue: Portworx license server is unreachable
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
      annotations:
        summary: Portworx instance {{$labels.instance}} is not able to reach the license server.
        description: Portworx license server is unreachable. Please check license
          server health and connection to license server.
    - alert: PortworxLicenseSetupError
      expr: px_alerts_floatinglicensesetuperror > 0
      labels:
        issue: Error setting up Portworx license
        severity: critical
        resource_type: portworx-node
        resource_name: "{{$labels.node}}"
        scrape_target_type: portworx-node
        scrape_target_name: "{{$labels.node}}"
      annotations:
        summary: Failed to set up Portworx license on {{$labels.instance}}.
        description: Failed to set up Portworx license on {{$labels.instance}}.
          Please check licenses and/or license server.
